# -*- coding: utf-8 -*-
"""07_02_TOKENTEXTSPLITTER.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18E4XsaydfXZiP9sKcVvAk4aytmK9wFdL
"""

import re

# 파일에서 키워드를 추출하고 포맷팅하는 함수
def format_keywords_from_file(file_path, target_titles):
    """
    주어진 파일에서 특정 키워드만 추출하고 구분선을 추가하여 출력합니다.

    Parameters:
        file_path (str): 읽어올 파일 경로
        target_titles (list): 출력할 키워드 제목 리스트

    Returns:
        str: 변환된 텍스트
    """
    # 파일 읽기
    with open(file_path, "r", encoding="utf-8") as f:
        file_content = f.read()

    # 블록 분리
    blocks = re.split(r'(?<=\n)(?=[A-Z][^\n]*\n)', file_content.strip())

    # 선택된 키워드만 변환
    selected_blocks = []
    for block in blocks:
        title = block.split("\n", 1)[0].strip()
        if title.upper() in target_titles:
            selected_blocks.append(block.strip())

    # 블록 사이에 구분선 추가
    return "\n\n----------------------------------------\n\n".join(selected_blocks)

# 파일 경로와 출력할 키워드 목록
file_path = "/content/appendix-keywords.txt"
target_titles = ["SEMANTIC SEARCH", "EMBEDDING", "TOKEN"]

# 변환된 결과 생성
formatted_text = format_keywords_from_file(file_path, target_titles)

# 결과 출력
print(formatted_text)